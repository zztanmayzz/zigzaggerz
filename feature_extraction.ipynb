{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO2bxLnb76NgpoVKLVcB+7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zztanmayzz/zigzaggerz/blob/main/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "Aosc4N9Mpxmt"
      },
      "outputs": [],
      "source": [
        "#!pip install tensorflow>=2.8.0 opencv-python numpy matplotlib scikit-learn rasterio geopandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import glob"
      ],
      "metadata": {
        "id": "e8XU94B1qSBo"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- U-Net Model Definition ---\n",
        "class MultiFeatureExtractor:\n",
        "    def __init__(self, input_shape=(512,512,3)):\n",
        "        self.input_shape = input_shape\n",
        "        self.model = self.build_model()\n",
        "        self.compile_model()\n",
        "\n",
        "    def build_unet_backbone(self, inputs):\n",
        "        c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
        "        c1 = layers.Conv2D(64, 3, activation='relu', padding='same')(c1)\n",
        "        p1 = layers.MaxPooling2D()(c1)\n",
        "        c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(p1)\n",
        "        c2 = layers.Conv2D(128, 3, activation='relu', padding='same')(c2)\n",
        "        p2 = layers.MaxPooling2D()(c2)\n",
        "        c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(p2)\n",
        "        c3 = layers.Conv2D(256, 3, activation='relu', padding='same')(c3)\n",
        "        p3 = layers.MaxPooling2D()(c3)\n",
        "        c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(p3)\n",
        "        c4 = layers.Conv2D(512, 3, activation='relu', padding='same')(c4)\n",
        "        p4 = layers.MaxPooling2D()(c4)\n",
        "        b = layers.Conv2D(1024, 3, activation='relu', padding='same')(p4)\n",
        "        b = layers.Conv2D(1024, 3, activation='relu', padding='same')(b)\n",
        "        return [c1, c2, c3, c4], b\n",
        "\n",
        "    def build_decoder_branch(self, x, skips, out_ch, activation, name):\n",
        "        c1, c2, c3, c4 = skips\n",
        "        u1 = layers.UpSampling2D()(x)\n",
        "        u1 = layers.Conv2D(512, 2, activation='relu', padding='same')(u1)\n",
        "        m1 = layers.concatenate([c4, u1])\n",
        "        c5 = layers.Conv2D(512, 3, activation='relu', padding='same')(m1)\n",
        "        c5 = layers.Conv2D(512, 3, activation='relu', padding='same')(c5)\n",
        "        u2 = layers.UpSampling2D()(c5)\n",
        "        u2 = layers.Conv2D(256, 2, activation='relu', padding='same')(u2)\n",
        "        m2 = layers.concatenate([c3, u2])\n",
        "        c6 = layers.Conv2D(256, 3, activation='relu', padding='same')(m2)\n",
        "        c6 = layers.Conv2D(256, 3, activation='relu', padding='same')(c6)\n",
        "        u3 = layers.UpSampling2D()(c6)\n",
        "        u3 = layers.Conv2D(128, 2, activation='relu', padding='same')(u3)\n",
        "        m3 = layers.concatenate([c2, u3])\n",
        "        c7 = layers.Conv2D(128, 3, activation='relu', padding='same')(m3)\n",
        "        c7 = layers.Conv2D(128, 3, activation='relu', padding='same')(c7)\n",
        "        u4 = layers.UpSampling2D()(c7)\n",
        "        u4 = layers.Conv2D(64, 2, activation='relu', padding='same')(u4)\n",
        "        m4 = layers.concatenate([c1, u4])\n",
        "        c8 = layers.Conv2D(64, 3, activation='relu', padding='same')(m4)\n",
        "        c8 = layers.Conv2D(64, 3, activation='relu', padding='same')(c8)\n",
        "        return layers.Conv2D(out_ch, 1, activation=activation, name=name)(c8)\n",
        "\n",
        "    def build_model(self):\n",
        "        inp = layers.Input(self.input_shape)\n",
        "        skips, bridge = self.build_unet_backbone(inp)\n",
        "        roads = self.build_decoder_branch(bridge, skips, 1, 'sigmoid', 'roads')\n",
        "        return models.Model(inp, roads)\n",
        "\n",
        "    def compile_model(self):\n",
        "        self.model.compile(optimizer='adam',\n",
        "                           loss='binary_crossentropy',\n",
        "                           metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)])"
      ],
      "metadata": {
        "id": "TdhEDawjtUKv"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For uploading Kaggle API Token\n",
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "metadata": {
        "id": "-3UTDrSruKLA"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Moving the API key\n",
        "#!mkdir -p ~/.kaggle && mv \"kaggle(1).json\" ~/.kaggle/kaggle.json && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Yb_4Bp42vEKJ"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gather dataset\n",
        "# Download and unzip DeepGlobe Road Extraction Dataset\n",
        "#!kaggle datasets download -d balraj98/deepglobe-road-extraction-dataset\n",
        "#!unzip -q deepglobe-road-extraction-dataset.zip -d deepglobe_data\n"
      ],
      "metadata": {
        "id": "CXMk0wfAw0eG"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# Functions to load images and masks\n",
        "def load_image_mask(img_path, mask_path):\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = tf.image.resize(image, (512,512))\n",
        "    image = image / 255.0\n",
        "\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.image.resize(mask, (512,512))\n",
        "    mask = mask / 255.0\n",
        "    mask = tf.round(mask)\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "def data_generator(img_files, mask_files, batch_size=8, repeat=False):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((img_files, mask_files))\n",
        "    dataset = dataset.shuffle(1000)\n",
        "    dataset = dataset.map(load_image_mask, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    if repeat:\n",
        "        dataset = dataset.repeat()\n",
        "    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Collect image and mask paths\n",
        "IMG_DIR = 'deepglobe_data/train/images'\n",
        "MASK_DIR = 'deepglobe_data/train/masks'\n",
        "\n",
        "img_files = sorted(glob.glob(os.path.join(IMG_DIR, '*.png')))\n",
        "mask_files = sorted(glob.glob(os.path.join(MASK_DIR, '*.png')))\n",
        "\n",
        "# Train-validation split\n",
        "split_idx = int(0.8 * len(img_files))\n",
        "train_imgs, val_imgs = img_files[:split_idx], img_files[split_idx:]\n",
        "train_masks, val_masks = mask_files[:split_idx], mask_files[split_idx:]\n",
        "\n",
        "# Convert to TensorFlow string tensors\n",
        "train_imgs = tf.convert_to_tensor(train_imgs, dtype=tf.string)\n",
        "train_masks = tf.convert_to_tensor(train_masks, dtype=tf.string)\n",
        "val_imgs = tf.convert_to_tensor(val_imgs, dtype=tf.string)\n",
        "val_masks = tf.convert_to_tensor(val_masks, dtype=tf.string)\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 8\n",
        "\n",
        "# Create TensorFlow datasets\n",
        "train_ds = data_generator(train_imgs, train_masks, batch_size=batch_size, repeat=True)\n",
        "val_ds = data_generator(val_imgs, val_masks, batch_size=batch_size)\n",
        "\n",
        "# Instantiate model\n",
        "extractor = MultiFeatureExtractor(input_shape=(512,512,3))\n"
      ],
      "metadata": {
        "id": "Zw7Pl1nDxHd6"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate steps per epoch\n",
        "steps_per_epoch = max(len(train_imgs) // batch_size, 1)\n",
        "validation_steps = max(len(val_imgs) // batch_size, 1)\n",
        "\n",
        "# Train the model with explicit steps per epoch and validation steps\n",
        "history = extractor.model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=20,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXZtK3D00oCJ",
        "outputId": "b9cc19b5-920d-44c6-9276-d1c059c4f23b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m113s\u001b[0m 113s/step\n",
            "Epoch 2/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Epoch 3/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Epoch 4/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Epoch 5/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step\n",
            "Epoch 6/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Epoch 7/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Epoch 8/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Epoch 9/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "Epoch 10/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "Epoch 11/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n",
            "Epoch 12/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "Epoch 13/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "Epoch 14/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "Epoch 15/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "Epoch 16/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "Epoch 17/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
            "Epoch 18/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 266ms/step\n",
            "Epoch 19/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
            "Epoch 20/20\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kwRFoifGA8WG"
      },
      "execution_count": 82,
      "outputs": []
    }
  ]
}