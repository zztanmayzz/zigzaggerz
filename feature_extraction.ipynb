{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUDzy/0pzNnZtMM2mr90Yu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zztanmayzz/zigzaggerz/blob/main/feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Aosc4N9Mpxmt"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow>=2.8.0 opencv-python numpy matplotlib scikit-learn rasterio geopandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import rasterio\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "e8XU94B1qSBo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 1. Model Definition: Multi-Task U-Net\n",
        "# =============================================================================\n",
        "\n",
        "class MultiFeatureExtractor:\n",
        "    def __init__(self, input_shape=(256,256,3), num_classes_terrain=2):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes_terrain = num_classes_terrain\n",
        "        self.model = self.build_model()\n",
        "        self.compile_model()\n",
        "\n",
        "    def build_unet_backbone(self, inputs):\n",
        "        c1 = layers.Conv2D(64,3,activation='relu',padding='same')(inputs)\n",
        "        c1 = layers.Conv2D(64,3,activation='relu',padding='same')(c1)\n",
        "        p1 = layers.MaxPooling2D()(c1)\n",
        "        c2 = layers.Conv2D(128,3,activation='relu',padding='same')(p1)\n",
        "        c2 = layers.Conv2D(128,3,activation='relu',padding='same')(c2)\n",
        "        p2 = layers.MaxPooling2D()(c2)\n",
        "        c3 = layers.Conv2D(256,3,activation='relu',padding='same')(p2)\n",
        "        c3 = layers.Conv2D(256,3,activation='relu',padding='same')(c3)\n",
        "        p3 = layers.MaxPooling2D()(c3)\n",
        "        c4 = layers.Conv2D(512,3,activation='relu',padding='same')(p3)\n",
        "        c4 = layers.Conv2D(512,3,activation='relu',padding='same')(c4)\n",
        "        p4 = layers.MaxPooling2D()(c4)\n",
        "        b  = layers.Conv2D(1024,3,activation='relu',padding='same')(p4)\n",
        "        b  = layers.Conv2D(1024,3,activation='relu',padding='same')(b)\n",
        "        return [c1,c2,c3,c4], b\n",
        "\n",
        "    def build_decoder_branch(self, x, skips, out_ch, activation, name):\n",
        "        c1,c2,c3,c4 = skips\n",
        "        u1 = layers.UpSampling2D()(x)\n",
        "        u1 = layers.Conv2D(512,2,activation='relu',padding='same')(u1)\n",
        "        m1 = layers.concatenate([c4,u1])\n",
        "        c5 = layers.Conv2D(512,3,activation='relu',padding='same')(m1)\n",
        "        c5 = layers.Conv2D(512,3,activation='relu',padding='same')(c5)\n",
        "        u2 = layers.UpSampling2D()(c5)\n",
        "        u2 = layers.Conv2D(256,2,activation='relu',padding='same')(u2)\n",
        "        m2 = layers.concatenate([c3,u2])\n",
        "        c6 = layers.Conv2D(256,3,activation='relu',padding='same')(m2)\n",
        "        c6 = layers.Conv2D(256,3,activation='relu',padding='same')(c6)\n",
        "        u3 = layers.UpSampling2D()(c6)\n",
        "        u3 = layers.Conv2D(128,2,activation='relu',padding='same')(u3)\n",
        "        m3 = layers.concatenate([c2,u3])\n",
        "        c7 = layers.Conv2D(128,3,activation='relu',padding='same')(m3)\n",
        "        c7 = layers.Conv2D(128,3,activation='relu',padding='same')(c7)\n",
        "        u4 = layers.UpSampling2D()(c7)\n",
        "        u4 = layers.Conv2D(64,2,activation='relu',padding='same')(u4)\n",
        "        m4 = layers.concatenate([c1,u4])\n",
        "        c8 = layers.Conv2D(64,3,activation='relu',padding='same')(m4)\n",
        "        c8 = layers.Conv2D(64,3,activation='relu',padding='same')(c8)\n",
        "        return layers.Conv2D(out_ch,1,activation=activation, name=name)(c8)\n",
        "\n",
        "    def build_model(self):\n",
        "        inp = layers.Input(self.input_shape)\n",
        "        skips, bridge = self.build_unet_backbone(inp)\n",
        "        roads   = self.build_decoder_branch(bridge, skips, 1, 'sigmoid', 'roads')\n",
        "        water   = self.build_decoder_branch(bridge, skips, 1, 'sigmoid', 'water')\n",
        "        elev    = self.build_decoder_branch(bridge, skips, 1, 'linear',  'elevation')\n",
        "        terrain = self.build_decoder_branch(bridge, skips, self.num_classes_terrain, 'softmax', 'terrain')\n",
        "        return models.Model(inp, [roads, water, elev, terrain])\n",
        "\n",
        "    def compile_model(self):\n",
        "        losses = {\n",
        "            'roads':     'binary_crossentropy',\n",
        "            'water':     'binary_crossentropy',\n",
        "            'elevation': 'mse',\n",
        "            'terrain':   'categorical_crossentropy'\n",
        "        }\n",
        "        loss_weights = {'roads':1.0,'water':1.0,'elevation':0.5,'terrain':1.0}\n",
        "        metrics = {\n",
        "            'roads':     ['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)],\n",
        "            'water':     ['accuracy', tf.keras.metrics.MeanIoU(num_classes=2)],\n",
        "            'elevation': ['mae'],\n",
        "            'terrain':   ['accuracy']\n",
        "        }\n",
        "        self.model.compile(optimizer='adam',\n",
        "                           loss=losses,\n",
        "                           loss_weights=loss_weights,\n",
        "                           metrics=metrics)"
      ],
      "metadata": {
        "id": "TdhEDawjtUKv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#For uploading Kaggle API Token\n",
        "#from google.colab import files\n",
        "#files.upload()"
      ],
      "metadata": {
        "id": "-3UTDrSruKLA"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Moving the API key\n",
        "#!mkdir -p ~/.kaggle && mv \"kaggle(1).json\" ~/.kaggle/kaggle.json && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "Yb_4Bp42vEKJ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Gather dataset\n",
        "!mkdir -p spacenet/images spacenet/masks\n",
        "\n",
        "# Example file URLs (replace with actual file names)\n",
        "!wget https://spacenet-dataset.s3.amazonaws.com/SpaceNet_AOI_1_Rio_Raw/RGB-PanSharpen/AOI_1_Rio_000000_0_0_RGB.tif -P spacenet/images/\n",
        "!wget https://spacenet-dataset.s3.amazonaws.com/SpaceNet_AOI_1_Rio_Buildings/AOI_1_Rio_000000_0_0_buildings.png -P spacenet/masks/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXMk0wfAw0eG",
        "outputId": "71162a00-8b13-4fab-a953-de81d55d70e6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-21 10:50:46--  https://spacenet-dataset.s3.amazonaws.com/SpaceNet_AOI_1_Rio_Raw/RGB-PanSharpen/AOI_1_Rio_000000_0_0_RGB.tif\n",
            "Resolving spacenet-dataset.s3.amazonaws.com (spacenet-dataset.s3.amazonaws.com)... 52.216.248.212, 52.217.233.209, 54.231.236.129, ...\n",
            "Connecting to spacenet-dataset.s3.amazonaws.com (spacenet-dataset.s3.amazonaws.com)|52.216.248.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-09-21 10:50:46 ERROR 404: Not Found.\n",
            "\n",
            "--2025-09-21 10:50:46--  https://spacenet-dataset.s3.amazonaws.com/SpaceNet_AOI_1_Rio_Buildings/AOI_1_Rio_000000_0_0_buildings.png\n",
            "Resolving spacenet-dataset.s3.amazonaws.com (spacenet-dataset.s3.amazonaws.com)... 52.216.248.212, 52.217.233.209, 54.231.236.129, ...\n",
            "Connecting to spacenet-dataset.s3.amazonaws.com (spacenet-dataset.s3.amazonaws.com)|52.216.248.212|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2025-09-21 10:50:46 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 2. Data Pipeline (with Rasterio for elevation)\n",
        "# =============================================================================\n",
        "\n",
        "TARGET_SIZE = (256,256)\n",
        "\n",
        "def load_elevation_with_rasterio(path, target_size=TARGET_SIZE):\n",
        "    with rasterio.open(path) as src:\n",
        "        elev = src.read(1).astype('float32')\n",
        "    elev = (elev - elev.min()) / (elev.max() - elev.min() + 1e-8)\n",
        "    elev = tf.image.resize(elev[..., np.newaxis], target_size)\n",
        "    return elev\n",
        "\n",
        "def parse_image_and_masks(img_path, roads_path, water_path, elev_path, terrain_path):\n",
        "    img = tf.io.read_file(img_path)\n",
        "    img = tf.image.decode_png(img, channels=3)\n",
        "    img = tf.image.resize(img, TARGET_SIZE) / 255.0\n",
        "\n",
        "    r = tf.io.read_file(roads_path)\n",
        "    r = tf.image.decode_png(r, channels=1)\n",
        "    r = tf.image.resize(r, TARGET_SIZE) / 255.0\n",
        "\n",
        "    w = tf.io.read_file(water_path)\n",
        "    w = tf.image.decode_png(w, channels=1)\n",
        "    w = tf.image.resize(w, TARGET_SIZE) / 255.0\n",
        "\n",
        "    def _load_elev(p):\n",
        "        return load_elevation_with_rasterio(p.numpy().decode(), TARGET_SIZE)\n",
        "    e = tf.py_function(_load_elev, [elev_path], tf.float32)\n",
        "    e.set_shape([*TARGET_SIZE,1])\n",
        "\n",
        "    t = tf.io.read_file(terrain_path)\n",
        "    t = tf.image.decode_png(t, channels=1)\n",
        "    t = tf.image.resize(t, TARGET_SIZE) / 255.0\n",
        "    t = tf.one_hot(tf.squeeze(tf.cast(t>0.5, tf.int32), axis=-1), depth=2)\n",
        "\n",
        "    return img, {'roads':r, 'water':w, 'elevation':e, 'terrain':t}\n",
        "\n",
        "def create_dataset(img_paths, roads_paths, water_paths, elev_paths, terrain_paths,\n",
        "                   batch=8, shuffle=True):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(\n",
        "        (img_paths, roads_paths, water_paths, elev_paths, terrain_paths))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(len(img_paths))\n",
        "    ds = ds.map(parse_image_and_masks, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n"
      ],
      "metadata": {
        "id": "Zw7Pl1nDxHd6"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 3. Training Script\n",
        "# =============================================================================\n",
        "\n",
        "def train_pipeline(train_imgs, train_roads, train_water,\n",
        "                   train_elev,  train_terrain,\n",
        "                   val_imgs,   val_roads,   val_water,\n",
        "                   val_elev,    val_terrain,\n",
        "                   epochs=50):\n",
        "    extractor = MultiFeatureExtractor(input_shape=(*TARGET_SIZE,3))\n",
        "    train_ds = create_dataset(train_imgs, train_roads, train_water,\n",
        "                              train_elev, train_terrain, batch=8, shuffle=True)\n",
        "    val_ds   = create_dataset(val_imgs,   val_roads,   val_water,\n",
        "                              val_elev,   val_terrain,   batch=8, shuffle=False)\n",
        "    extractor.model.fit(train_ds,\n",
        "                        validation_data=val_ds,\n",
        "                        epochs=epochs,\n",
        "                        callbacks=[\n",
        "                            keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True),\n",
        "                            keras.callbacks.ReduceLROnPlateau(patience=5),\n",
        "                            keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
        "                        ])\n",
        "    return extractor\n"
      ],
      "metadata": {
        "id": "wXXjUauq0ifZ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 4. Inference Utility\n",
        "# =============================================================================\n",
        "\n",
        "def preprocess_raw_image(path, input_size=TARGET_SIZE):\n",
        "    img = cv2.imread(path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    img = cv2.resize(img, input_size) / 255.0\n",
        "    return np.expand_dims(img.astype('float32'), axis=0)\n",
        "\n",
        "def run_inference(model, raw_img_path):\n",
        "    batch = preprocess_raw_image(raw_img_path)\n",
        "    preds = model.predict(batch)\n",
        "    roads_prob = preds[0][0,:,:,0]\n",
        "    water_prob = preds[1][0,:,:,0]\n",
        "    elev_map   = preds[2][0,:,:,0]\n",
        "    terrain_cls= np.argmax(preds[3][0], axis=-1)\n",
        "    return roads_prob, water_prob, elev_map, terrain_cls"
      ],
      "metadata": {
        "id": "dXZtK3D00oCJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 5. Visualization Example\n",
        "# =============================================================================\n",
        "\n",
        "def visualize_predictions(raw_path, roads, water, elev, terrain):\n",
        "    img = cv2.cvtColor(cv2.imread(raw_path), cv2.COLOR_BGR2RGB)\n",
        "    h, w, _ = img.shape\n",
        "    roads   = cv2.resize(roads,   (w,h))\n",
        "    water   = cv2.resize(water,   (w,h))\n",
        "    elev    = cv2.resize(elev,    (w,h))\n",
        "    terrain = cv2.resize(terrain.astype('float32'), (w,h))\n",
        "\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.subplot(2,3,1); plt.imshow(img);      plt.title('Original'); plt.axis('off')\n",
        "    plt.subplot(2,3,2); plt.imshow(roads, cmap='Reds');    plt.title('Roads');    plt.axis('off')\n",
        "    plt.subplot(2,3,3); plt.imshow(water, cmap='Blues');   plt.title('Water');    plt.axis('off')\n",
        "    plt.subplot(2,3,4); plt.imshow(elev,  cmap='terrain'); plt.title('Elevation'); plt.axis('off')\n",
        "    plt.subplot(2,3,5); plt.imshow(terrain, cmap='viridis');plt.title('Terrain');   plt.axis('off')\n",
        "    plt.tight_layout(); plt.show()"
      ],
      "metadata": {
        "id": "agde1G2O0rdr"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =============================================================================\n",
        "# 6. Example Usage: Ensure Mask Files Exist\n",
        "# =============================================================================\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    import glob\n",
        "\n",
        "    IMG_TRAIN_DIR    = 'images/train/'\n",
        "    MASK_TRAIN_DIR   = 'masks/train/'\n",
        "    IMG_VAL_DIR      = 'images/val/'\n",
        "    MASK_VAL_DIR     = 'masks/val/'\n",
        "\n",
        "    train_imgs = sorted(glob.glob(os.path.join(IMG_TRAIN_DIR, 'img_*.png')))\n",
        "    val_imgs = sorted(glob.glob(os.path.join(IMG_VAL_DIR, 'img_*.png')))\n",
        "\n",
        "    train_roads, train_water, train_elev, train_terrain = [], [], [], []\n",
        "    for img_path in train_imgs:\n",
        "        base = os.path.splitext(os.path.basename(img_path))[0].split('_')[-1]\n",
        "        roads_p   = os.path.join(MASK_TRAIN_DIR, f'roads_{base}.png')\n",
        "        water_p   = os.path.join(MASK_TRAIN_DIR, f'water_{base}.png')\n",
        "        elev_p    = os.path.join(MASK_TRAIN_DIR, f'elev_{base}.tif')\n",
        "        terrain_p = os.path.join(MASK_TRAIN_DIR, f'terrain_{base}.png')\n",
        "        if all(os.path.exists(p) for p in (roads_p, water_p, elev_p, terrain_p)):\n",
        "            train_roads.append(roads_p)\n",
        "            train_water.append(water_p)\n",
        "            train_elev.append(elev_p)\n",
        "            train_terrain.append(terrain_p)\n",
        "\n",
        "    val_roads, val_water, val_elev, val_terrain = [], [], [], []\n",
        "    for img_path in val_imgs:\n",
        "        base = os.path.splitext(os.path.basename(img_path))[0].split('_')[-1]\n",
        "        roads_p   = os.path.join(MASK_VAL_DIR, f'roads_{base}.png')\n",
        "        water_p   = os.path.join(MASK_VAL_DIR, f'water_{base}.png')\n",
        "        elev_p    = os.path.join(MASK_VAL_DIR, f'elev_{base}.tif')\n",
        "        terrain_p = os.path.join(MASK_VAL_DIR, f'terrain_{base}.png')\n",
        "        if all(os.path.exists(p) for p in (roads_p, water_p, elev_p, terrain_p)):\n",
        "            val_roads.append(roads_p)\n",
        "            val_water.append(water_p)\n",
        "            val_elev.append(elev_p)\n",
        "            val_terrain.append(terrain_p)\n",
        "\n",
        "    print(f'Training on {len(train_roads)} samples.')\n",
        "    print(f'Validation on {len(val_roads)} samples.')\n",
        "\n",
        "    if len(train_roads) == 0 or len(val_roads) == 0:\n",
        "        raise RuntimeError(\"No matching mask files found. Please check your directory paths and mask filenames.\")\n",
        "\n",
        "    extractor = train_pipeline(\n",
        "        train_imgs, train_roads, train_water, train_elev, train_terrain,\n",
        "        val_imgs, val_roads, val_water, val_elev, val_terrain,\n",
        "        epochs=30\n",
        "    )\n",
        "\n",
        "    extractor.model.load_weights('best_model.h5')\n",
        "    raw_tile = 'isro_tiles/tile_000.png'\n",
        "    roads_p, water_p, elev_p, terrain_c = run_inference(extractor.model, raw_tile)\n",
        "    visualize_predictions(raw_tile, roads_p, water_p, elev_p, terrain_c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "G2jYvFTz1Py2",
        "outputId": "a2b64131-a44f-40d4-9b48-210dd92b17e1"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on 0 samples.\n",
            "Validation on 0 samples.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "No matching mask files found. Please check your directory paths and mask filenames.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3309119562.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_roads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_roads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No matching mask files found. Please check your directory paths and mask filenames.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     extractor = train_pipeline(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No matching mask files found. Please check your directory paths and mask filenames."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws s3 ls --no-sign-request s3://spacenet-dataset/SpaceNet_AOI_1_Rio_Raw/RGB-PanSharpen/ | head -20\n",
        "!aws s3 ls --no-sign-request s3://spacenet-dataset/SpaceNet_AOI_1_Rio_Buildings/ | head -20\n"
      ],
      "metadata": {
        "id": "PH2z8ZD-5OXz"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hVtrdGgs6gn8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}